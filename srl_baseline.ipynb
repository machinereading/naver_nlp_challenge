{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import read_data\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from optparse import OptionParser\n",
    "import torch.autograd as autograd\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "today = start_time.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = read_data.load_trn_data()\n",
    "trn_conll = read_data.load_trn_nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "# [\n",
    "#     ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'], \n",
    "#     ['인사동에', '들어서면', '다종다양의', '창호지,', '도자기', '등', '고미술품들이', '진열장에', '즐비하게', '널려져', '있는', '것을', '볼', '수', '있다.'], \n",
    "#     ['ARGM-LOC', '-', '-', '-', '-', '-', 'ARG1', 'ARG1', '-', '-', '-', 'ARG1', '-', '-', '-']\n",
    "# ]\n",
    "\n",
    "def get_input_data(data):\n",
    "    result = []\n",
    "    for sent in data:\n",
    "        sent_list = []\n",
    "        \n",
    "        tok_idx = []\n",
    "        tok_str = []\n",
    "        tok_arg = []\n",
    "        for token in sent:\n",
    "            tok_idx.append(token[0])\n",
    "            tok_str.append(token[1])\n",
    "            tok_arg.append(token[2])\n",
    "            \n",
    "        sent_list.append(tok_idx)\n",
    "        sent_list.append(tok_str)\n",
    "        sent_list.append(tok_arg)\n",
    "        result.append(sent_list)\n",
    "    return result\n",
    "        \n",
    "input_data = get_input_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_sent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-7c7a2687c0ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdev_sent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgold_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./dev.data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_sent' is not defined"
     ]
    }
   ],
   "source": [
    "div = len(input_data) - dev_sent\n",
    "dev = input_data[div:]\n",
    "trn = input_data[:div]\n",
    "gold_file = './dev.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP_VOCAB_SIZE: 32\n",
      "ARG_VOCAB_SIZE: 18\n"
     ]
    }
   ],
   "source": [
    "def prepare_idx():\n",
    "    dp_to_ix, arg_to_ix = {},{}\n",
    "    dp_to_ix['null'] = 0\n",
    "    for sent in trn_conll:\n",
    "        for token in sent:\n",
    "            dp = token[11]\n",
    "            if dp not in dp_to_ix:\n",
    "                dp_to_ix[dp] = len(dp_to_ix)\n",
    "    \n",
    "    args = ['ARG0', 'ARG1', 'ARG2', 'ARG3', 'ARGM-CAU', 'ARGM-CND', 'ARGM-DIR', 'ARM-DIS', 'ARGM-INS', 'ARGM-LOC', 'ARCM-MNR', 'ARCM-NEG', 'ARCM-PRD', 'ARCM-PRP', 'ARCM-TMP', 'ARCM-ADV', 'ARCM-EXT', '-']\n",
    "    for i in args:\n",
    "        if i not in arg_to_ix:\n",
    "            arg_to_ix[i] = len(arg_to_ix)\n",
    "    return dp_to_ix, arg_to_ix\n",
    "dp_to_ix, arg_to_ix = prepare_idx()\n",
    "DP_VOCAB_SIZE = len(dp_to_ix)\n",
    "ARG_VOCAB_SIZE = len(arg_to_ix)\n",
    "print('DP_VOCAB_SIZE:',DP_VOCAB_SIZE)\n",
    "print('ARG_VOCAB_SIZE:',ARG_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### CONFIGURATION ###\n",
      "\n",
      "{'arg_dim': 4,\n",
      " 'dp_dim': 4,\n",
      " 'dp_label_dim': 10,\n",
      " 'dropout_rate': 0.01,\n",
      " 'feat_dim': 2,\n",
      " 'hidden_dim': 64,\n",
      " 'learning_rate': 0.001,\n",
      " 'lstm_depth': 2,\n",
      " 'lstm_dim': 64,\n",
      " 'lstm_input_dim': 768,\n",
      " 'lu_pos_dim': 5,\n",
      " 'model_path': './result/baseline',\n",
      " 'num_epochs': 50,\n",
      " 'position_feature_dim': 5,\n",
      " 'pretrained_embedding_dim': 300,\n",
      " 'token_dim': 60}\n",
      "\n",
      "\n",
      "### YOUR MODEL WILL BE SAVED TO ./result/baseline ###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configuration = {'token_dim': 60,\n",
    "                 'hidden_dim': 64,\n",
    "                 'feat_dim': 2,\n",
    "                 'dp_dim': 4,\n",
    "                 'arg_dim': 4,\n",
    "                 'lu_pos_dim': 5,\n",
    "                 'dp_label_dim': 10,\n",
    "                 'lstm_input_dim': 768,\n",
    "                 'lstm_dim': 64,\n",
    "                 'lstm_depth': 2,\n",
    "                 'hidden_dim': 64,\n",
    "                 'position_feature_dim': 5,\n",
    "                 'num_epochs': 50,\n",
    "                 'learning_rate': 0.001,\n",
    "                 'dropout_rate': 0.01,\n",
    "                 'pretrained_embedding_dim': 300,\n",
    "                 'model_path': './result/baseline'\n",
    "                 }\n",
    "print('\\n### CONFIGURATION ###\\n')\n",
    "pprint.pprint(configuration)\n",
    "print('')\n",
    "\n",
    "DPDIM = configuration['dp_dim']\n",
    "ARGDIM = configuration['arg_dim']\n",
    "LSTMINPDIM = configuration['lstm_input_dim']\n",
    "FEATDIM = configuration['feat_dim']\n",
    "HIDDENDIM = configuration['hidden_dim']\n",
    "LSTMDEPTH = configuration['lstm_depth']\n",
    "DROPOUT_RATE = configuration['dropout_rate']\n",
    "learning_rate = configuration['learning_rate']\n",
    "NUM_EPOCHS = configuration['num_epochs']\n",
    "model_path = configuration['model_path']\n",
    "\n",
    "print('\\n### YOUR MODEL WILL BE SAVED TO', model_path, '###\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/06/2018 15:13:22 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-vocab.txt from cache at /home/hahmyg/.pytorch_pretrained_bert/3f396e8b6d1942457b908bd7f351fa991ead4c4adef76c76189a9ace12841860.535306b226c42cebebbc0dabc83b92ab11260e9919e21e2ab0beb301f267b4c7\n",
      "12/06/2018 15:13:23 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual.tar.gz from cache at /home/hahmyg/.pytorch_pretrained_bert/e359baa6e6b29d9971ac7525c83e8cad6f15dce9d8ec9bfdeafa149a7a2191c9.5e2593d7d76d4df2b618714d71af902c02a5f51c1b2d050399e1cb36b7bb2eeb\n",
      "12/06/2018 15:13:23 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/hahmyg/.pytorch_pretrained_bert/e359baa6e6b29d9971ac7525c83e8cad6f15dce9d8ec9bfdeafa149a7a2191c9.5e2593d7d76d4df2b618714d71af902c02a5f51c1b2d050399e1cb36b7bb2eeb to temp dir /tmp/tmp09esgg9i\n",
      "12/06/2018 15:13:30 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load BERT model\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual')\n",
    "bert_model = BertModel.from_pretrained('bert-base-multilingual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(tokens):\n",
    "    bert_tokens = []\n",
    "    orig_to_token_map = []\n",
    "    bert_tokens.append(\"[CLS]\")\n",
    "    for i in range(len(tokens)):\n",
    "        origin_token = tokens[i]\n",
    "        orig_to_token_map.append(len(bert_tokens))\n",
    "        bert_tokens.extend(tokenizer.tokenize(origin_token))\n",
    "    \n",
    "    return bert_tokens, orig_to_token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_idxs(conll):\n",
    "    result = []\n",
    "    preds = [0 for i in range(len(conll))]\n",
    "    for i in range(len(conll)):\n",
    "        tok = conll[i]\n",
    "        if tok[10].startswith('V'):\n",
    "            preds = [0 for item in range(len(conll))]\n",
    "            preds[i] = 1\n",
    "            result.append(preds)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arg_idxs(pred_idx, conll):\n",
    "    arg_idxs = [0 for i in range(len(conll))]\n",
    "    for i in range(len(conll)):\n",
    "        tok = conll[i]\n",
    "        if int(tok[8]) == pred_idx:\n",
    "            arg_pos = tok[-1]\n",
    "            if arg_pos[:2] == 'NP':\n",
    "                arg_idxs[i] = 1\n",
    "    return arg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(pred_idxs, conll):\n",
    "    result = []\n",
    "    for i in pred_idxs:\n",
    "#         print(i)\n",
    "        features = []\n",
    "        for j in range(len(i)):\n",
    "            pred_idx = i[j]\n",
    "            if pred_idx == 1:\n",
    "                arg_idxs = get_arg_idxs(j, conll)\n",
    "#                 print(arg_idxs)\n",
    "        for j in range(len(i)):\n",
    "            feature = []                \n",
    "            feature.append(i[j])\n",
    "            feature.append(arg_idxs[j])\n",
    "            features.append(feature)\n",
    "                \n",
    "        result.append(features)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    vocab = list(to_ix.keys())\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w in vocab:\n",
    "            idxs.append(to_ix[w])\n",
    "        else:\n",
    "            idxs.append(0)  \n",
    "#     return torch.tensor(idxs)\n",
    "    return torch.tensor(idxs).cuda()\n",
    "#     return torch.tensor(idxs).type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_vecs(tokens, args_in):\n",
    "      \n",
    "    text = ' '.join(tokens) \n",
    "    bert_tokens, orig_to_token_map = tokenization(tokens)\n",
    "    segments_ids = [0 for i in range(len(bert_tokens))]\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "    \n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    encoded_layers, pooled_output = bert_model(tokens_tensor, segments_tensors, output_all_encoded_layers=False)\n",
    "    \n",
    "    vecs = encoded_layers[0].cuda()\n",
    "    \n",
    "    return vecs, orig_to_token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dps(conll):\n",
    "    dps = []\n",
    "    for tok in conll:\n",
    "        dp = tok[10]\n",
    "        dps.append(dp)\n",
    "    return dps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_by_tensor(t):\n",
    "    value, indices = t.max(1)\n",
    "    score = pow(1, value)\n",
    "    labels = []\n",
    "    for i in indices:\n",
    "        for label, idx in arg_to_ix.items():\n",
    "            if idx == i:\n",
    "                pred = label\n",
    "                labels.append(pred)\n",
    "                break\n",
    "    return labels, score\n",
    "            \n",
    "        \n",
    "    pred = None\n",
    "    for label, idx in arg_to_ix.items():\n",
    "        if idx == indices:\n",
    "            pred = label\n",
    "            break\n",
    "    return pred, score\n",
    "\n",
    "\n",
    "\n",
    "def eval_dev(my_model):\n",
    "    sent, golds, preds = [],[],[]\n",
    "    n = 0\n",
    "    for s_idx in range(len(dev)):\n",
    "        tokens, args = dev[s_idx][1], dev[s_idx][2]\n",
    "        args_in = prepare_sequence(args, arg_to_ix)  \n",
    "\n",
    "        conll = read_data.get_nlp_for_trn(s_idx+27884)\n",
    "        dps = get_dps(conll)\n",
    "        dp_in = prepare_sequence(dps, dp_to_ix)\n",
    "\n",
    "        pred_idxs = get_pred_idxs(conll)\n",
    "        features = get_feature(pred_idxs, conll)\n",
    "        features = torch.tensor(features).type(torch.cuda.FloatTensor)  \n",
    "\n",
    "\n",
    "        gold = args\n",
    "        pred = ['-' for i in range(len(args))]\n",
    "        for i in range(len(pred_idxs)):\n",
    "            input_vec = []\n",
    "            feat_vectors = features[i]\n",
    "            bert_vecs, orig_to_token_map = get_bert_vecs(tokens,args_in)\n",
    "\n",
    "            for tok_idx in range(len(feat_vectors)):\n",
    "                add_feat = torch.cat((bert_vecs[orig_to_token_map[tok_idx]], feat_vectors[tok_idx]))\n",
    "\n",
    "                input_vec.append(add_feat)\n",
    "            input_vec = torch.stack(input_vec)           \n",
    "\n",
    "            tag_scores = my_model(input_vec, dp_in)           \n",
    "            labels, score = get_labels_by_tensor(tag_scores)\n",
    "            \n",
    "            for idx in range(len(labels)):\n",
    "                label = labels[idx]\n",
    "                if label == '-':\n",
    "                    pass\n",
    "                else:\n",
    "                    if label[idx] == '-':\n",
    "                        label[idx] = label\n",
    "        for i in gold:\n",
    "            if i == '-': i = 'O'\n",
    "            else: i = 'S-'+i\n",
    "        for i in pred:\n",
    "            if i == '-': i = 'O'\n",
    "            else: i = 'S-'+i\n",
    "        \n",
    "        sent.append(tokens)\n",
    "        golds.append(gold)\n",
    "        preds.append(pred)    \n",
    "    \n",
    "    result = []\n",
    "    result.append(sent)\n",
    "    result.append(golds)\n",
    "    result.append(preds)\n",
    "    \n",
    "    f1 = f1_score(golds, preds)\n",
    "    report = classification_report(golds, preds)\n",
    "    \n",
    "    with open(model_path+'/result','w') as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=4)        \n",
    "    return f1, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.dp_embeddings = nn.Embedding(DP_VOCAB_SIZE, DPDIM)\n",
    "        \n",
    "        #LSTM layer        \n",
    "        self.lstm_tok = nn.LSTM(LSTMINPDIM+DPDIM+FEATDIM, HIDDENDIM//2, bidirectional=True, num_layers=LSTMDEPTH, dropout=DROPOUT_RATE)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # Linear\n",
    "        self.hidden2tag = nn.Linear(HIDDENDIM, tagset_size)\n",
    "              \n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(4, 1, HIDDENDIM//2).cuda(),\n",
    "            torch.zeros(4, 1, HIDDENDIM//2).cuda())\n",
    "    \n",
    "    def forward(self, input_vecs, dp_in):\n",
    "        \n",
    "        dp_embs = self.dp_embeddings(dp_in)\n",
    "        \n",
    "        input_embs = torch.cat( (input_vecs, dp_embs), 1)        \n",
    "        input_embs = input_embs.view(len(input_vecs), 1, -1)\n",
    "        \n",
    "        # LSTM layer\n",
    "        lstm_out_tok, self.hidden = self.lstm_tok(\n",
    "            input_embs, self.hidden)\n",
    "        \n",
    "        # Linear\n",
    "        tag_space = self.hidden2tag(lstm_out_tok.view(len(input_vecs),-1))        \n",
    "        tag_space = F.relu(tag_space)        \n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        tag_scores = softmax(tag_space)\n",
    "#         tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "srl_model = LSTMTagger(ARG_VOCAB_SIZE)\n",
    "srl_model.cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(srl_model.parameters(), lr=learning_rate)\n",
    "# optimizer = optim.SGD(srl_model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(trn)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    n_of_step = 0\n",
    "\n",
    "    for s_idx in range(len(trn)):\n",
    "        n_of_sent = 1\n",
    "        tokens, args = trn[s_idx][1], trn[s_idx][2]\n",
    "        args_in = prepare_sequence(args, arg_to_ix)  \n",
    "\n",
    "        conll = read_data.get_nlp_for_trn(s_idx)\n",
    "        dps = get_dps(conll)\n",
    "        dp_in = prepare_sequence(dps, dp_to_ix)\n",
    "\n",
    "        pred_idxs = get_pred_idxs(conll)\n",
    "\n",
    "        for i in range(len(pred_idxs)):\n",
    "            pred_seq = pred_idxs[i]\n",
    "            \n",
    "            for j in range(len(pred_seq)):\n",
    "                p = pred_seq[j]\n",
    "                if p == 1:\n",
    "                    pred_idx = j\n",
    "            arg_idxs = get_arg_idxs(pred_idx, conll)          \n",
    "            print(arg_idxs)\n",
    "            \n",
    "        break\n",
    "    break\n",
    "\n",
    "#         for i in range(len(pred_idxs)):\n",
    "#             input_vec = []\n",
    "#             feat_vectors = features[i]\n",
    "#             bert_vecs, orig_to_token_map = get_bert_vecs(tokens,args_in)\n",
    "\n",
    "\n",
    "\n",
    "#             for tok_idx in range(len(feat_vectors)):\n",
    "#                 add_feat = torch.cat((bert_vecs[orig_to_token_map[tok_idx]], feat_vectors[tok_idx]))\n",
    "\n",
    "#                 input_vec.append(add_feat)\n",
    "#             input_vec = torch.stack(input_vec)\n",
    "\n",
    "#             srl_model.zero_grad()\n",
    "#             srl_model.hidden = srl_model.init_hidden()\n",
    "\n",
    "            \n",
    "\n",
    "#             tag_scores = srl_model(input_vec, dp_in)\n",
    "#             loss = loss_function(tag_scores, args_in)\n",
    "#             loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(srl_model.parameters(), 0.25)\n",
    "#             optimizer.step()\n",
    "        \n",
    "#             n_of_step +=1\n",
    "\n",
    "#             if n_of_step % 100 == 0:\n",
    "#                 print('Epoch [{}/{}], Sent/Step [{}/{}], Loss: {:.4f}' \n",
    "#                        .format(epoch+1, NUM_EPOCHS, n_of_sent, n_of_step, loss.item()))\n",
    "#         n_of_sent +=1\n",
    "            \n",
    "#     f1, report = eval_dev(srl_model)\n",
    "#     print('Epoch [{}/{}], F1: {:4f}' \n",
    "#                    .format(epoch+1, NUM_EPOCHS, f1))\n",
    "\n",
    "# print('### report ###')\n",
    "# print(report)\n",
    "        \n",
    "# torch.save(srl_model, model_path)\n",
    "# print('')\n",
    "# print('### YOUR MODEL IS SAVED TO', model_path, '###')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8347807402367182\n",
      "0.8879443304227439\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ARG0       0.75      0.94      0.83     24715\n",
      "\n",
      "avg / total       0.75      0.94      0.83     24715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "golds = []\n",
    "preds = []\n",
    "\n",
    "for s_idx in range(len(dev)):\n",
    "    n_of_sent = 1\n",
    "    tokens, args = trn[s_idx][1], trn[s_idx][2]\n",
    "    args_in = prepare_sequence(args, arg_to_ix)  \n",
    "    conll = read_data.get_nlp_for_trn(s_idx)\n",
    "    dps = get_dps(conll)\n",
    "    dp_in = prepare_sequence(dps, dp_to_ix)\n",
    "    pred_idxs = get_pred_idxs(conll)\n",
    "    \n",
    "    gold = args\n",
    "\n",
    "    pred = ['O' for i in range(len(args))]\n",
    "    for i in range(len(pred_idxs)):\n",
    "        pred_seq = pred_idxs[i]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        for j in range(len(pred_seq)):\n",
    "            p = pred_seq[j]\n",
    "            if p == 1:\n",
    "                pred_idx = j\n",
    "        arg_idxs = get_arg_idxs(pred_idx, conll)\n",
    "        \n",
    "        labels = []\n",
    "        for idx in arg_idxs:\n",
    "            if idx == 1:\n",
    "                label = 'S-ARG0'\n",
    "            else:\n",
    "                label = 'O'\n",
    "            labels.append(label)\n",
    "                \n",
    "                \n",
    "        for idx in range(len(labels)):\n",
    "            label = labels[idx]\n",
    "            if label == 'O':\n",
    "                pass\n",
    "            else:\n",
    "                pred[idx] = label\n",
    "#                 print('wow')\n",
    "#                 print(label)\n",
    "#                 print(pred[idx])\n",
    "    \n",
    "    gold = []\n",
    "    for i in args:\n",
    "        if i == '-': \n",
    "            g = 'O'\n",
    "        else: \n",
    "            g = 'S-ARG0'\n",
    "        gold.append(g)\n",
    "\n",
    "    golds.append(gold)\n",
    "    preds.append(pred)\n",
    "\n",
    "#     print('gold')\n",
    "#     print(gold)\n",
    "#     print('pred')\n",
    "#     print(pred)\n",
    "#     print('')\n",
    "#     break\n",
    "        \n",
    "    \n",
    "f1 = f1_score(golds, preds)\n",
    "a = accuracy_score(golds,preds)\n",
    "report = classification_report(golds, preds)\n",
    "\n",
    "print(f1)\n",
    "print(a)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27752060604123824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "n = 0\n",
    "for i in range(len(golds)):\n",
    "    gold = golds[i]\n",
    "    pred = preds[i]\n",
    "    f1 = f1 + f1_score(gold, pred, average='macro')\n",
    "    \n",
    "    n +=1\n",
    "    \n",
    "result = f1/n\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
