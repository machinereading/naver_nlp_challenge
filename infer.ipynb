{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading TRAINING data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertModel\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import read_data\n",
    "import eval_srl\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "batch_size = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = read_data.load_trn_data()\n",
    "\n",
    "# input data\n",
    "# [\n",
    "#     ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'], \n",
    "#     ['인사동에', '들어서면', '다종다양의', '창호지,', '도자기', '등', '고미술품들이', '진열장에', '즐비하게', '널려져', '있는', '것을', '볼', '수', '있다.'], \n",
    "#     ['ARGM-LOC', '-', '-', '-', '-', '-', 'ARG1', 'ARG1', '-', '-', '-', 'ARG1', '-', '-', '-']\n",
    "# ]\n",
    "\n",
    "def get_input_data(data):\n",
    "    result = []\n",
    "    for sent in data:\n",
    "        sent_list = []\n",
    "        \n",
    "        tok_idx = []\n",
    "        tok_str = []\n",
    "        tok_arg = []\n",
    "        for token in sent:\n",
    "            tok_idx.append(token[0])\n",
    "            tok_str.append(token[1])\n",
    "            tok_arg.append(token[2])\n",
    "            \n",
    "        sent_list.append(tok_idx)\n",
    "        sent_list.append(tok_str)\n",
    "        sent_list.append(tok_arg)\n",
    "        result.append(sent_list)\n",
    "    return result\n",
    "        \n",
    "input_data = get_input_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vals = ['ARG0', 'ARG1', 'ARG2', 'ARG3', 'ARGM-EXT', 'ARGM-LOC', 'ARGM-DIR', 'ARGM-MNR', 'ARGM-TMP', 'ARGM-CAU', 'ARGM-INS', 'ARGM-PRP', '-']\n",
    "tag2idx = {}\n",
    "for i in tags_vals:\n",
    "    tag2idx[i] = len(tag2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/13/2018 23:26:00 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/hahmyg/.pytorch_pretrained_bert/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "def bert_tokenizer(text):\n",
    "    orig_tokens = text.split(' ')\n",
    "    bert_tokens = []\n",
    "    orig_to_tok_map = []\n",
    "    bert_tokens.append(\"[CLS]\")\n",
    "    for orig_token in orig_tokens:\n",
    "        orig_to_tok_map.append(len(bert_tokens))\n",
    "        bert_tokens.extend(tokenizer.tokenize(orig_token))\n",
    "    bert_tokens.append(\"[SEP]\")\n",
    "    \n",
    "    return orig_tokens, bert_tokens, orig_to_tok_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data example\n",
    "\n",
    "def example():\n",
    "    dummy = input_data[:500]\n",
    "    print(dummy[:2])\n",
    "    answer = [ d[2] for d in dummy ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_input(data):\n",
    "    tokenized_texts = []\n",
    "    \n",
    "    orig_to_tok_maps = []\n",
    "\n",
    "    for i in range(len(data)):    \n",
    "        d = data[i]\n",
    "        text = ' '.join(d[1])\n",
    "        orig_tokens, bert_tokens, orig_to_tok_map = bert_tokenizer(text)\n",
    "        orig_to_tok_maps.append(orig_to_tok_map)\n",
    "        tokenized_texts.append(bert_tokens)\n",
    "\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "#     tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "    attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n",
    "    \n",
    "    inputs = torch.tensor(input_ids)\n",
    "    input_masks = torch.tensor(attention_masks)\n",
    "    \n",
    "    return inputs, input_masks, orig_to_tok_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(data, model):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "   \n",
    "    inputs, input_masks, orig_to_tok_maps = gen_input(data)\n",
    "    \n",
    "    n = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input_idxs = inputs[i].view(1, len(inputs[i])).to(device)\n",
    "        input_mask = input_masks[i].view(1, len(input_masks[i])).to(device)\n",
    "        orig_to_tok_map = orig_to_tok_maps[i]       \n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_idxs, token_type_ids=None,\n",
    "                           attention_mask=input_mask)\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        \n",
    "        bert_pred = [list(p) for p in np.argmax(logits, axis=2)]\n",
    "        token_pred = []\n",
    "        for idx in orig_to_tok_map:\n",
    "            token_pred.append(bert_pred[0][idx])\n",
    "        \n",
    "        predictions.extend([token_pred])\n",
    "\n",
    "    pred_tags = [[tags_vals[p_i] for p_i in p] for p in predictions]\n",
    "    \n",
    "    return pred_tags\n",
    "    \n",
    "#     print(pred_tags)\n",
    "#     print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n",
    "#     print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "#     print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IO example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input example\n",
      "[[['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'], ['인사동에', '들어서면', '다종다양의', '창호지,', '도자기', '등', '고미술품들이', '진열장에', '즐비하게', '널려져', '있는', '것을', '볼', '수', '있다.'], ['ARGM-LOC', '-', '-', '-', '-', '-', 'ARG1', 'ARG1', '-', '-', '-', 'ARG1', '-', '-', '-']], [['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'], ['올림픽에', '출진하는', '선수라면', '어떤', '금전적', '인유가', '없더라도', '최악을', '다하겠다는', '정신력,', '욕망은', '차있다.'], ['ARG3', '-', 'ARG0', '-', '-', 'ARG1', '-', 'ARG1', '-', '-', 'ARG1', '-']]]\n",
      "\n",
      "output example\n",
      "[['ARGM-LOC', '-', '-', '-', '-', '-', 'ARG1', 'ARGM-LOC', '-', '-', '-', 'ARG1', '-', '-', '-'], ['ARG3', '-', 'ARG0', '-', '-', 'ARG1', '-', 'ARG1', '-', '-', 'ARG1', '-']]\n",
      "\n",
      "f1: 0.9135802469135801\n"
     ]
    }
   ],
   "source": [
    "def example():\n",
    "    # 1) load MODEL\n",
    "    model = torch.load('./result/model-bert/basic-model.pt')\n",
    "    \n",
    "    # 2) Input example\n",
    "    print('\\ninput example')\n",
    "    dummy = input_data[:50]\n",
    "    print(dummy[:2])\n",
    "    \n",
    "    # 3) infer example\n",
    "    pred = infer(dummy, model)\n",
    "    print('\\noutput example')\n",
    "    print(pred[:2])\n",
    "    \n",
    "    # 4) evaluation example\n",
    "    answer = [ d[2] for d in dummy ]\n",
    "    gold = []\n",
    "    for i in dummy:\n",
    "        gold += i[2]\n",
    "    predict = []\n",
    "    for i in pred:\n",
    "        predict += i\n",
    "        \n",
    "    f1 = eval_srl.evaluate_from_list(predict, gold)\n",
    "    print('\\nf1:', f1)\n",
    "    \n",
    "# example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
