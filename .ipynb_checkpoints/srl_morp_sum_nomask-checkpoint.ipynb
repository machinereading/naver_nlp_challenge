{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading TRAINING data...\n",
      "# of sentences: 34856\n",
      "# of arg_types\n",
      "\ttotal: 124873 (3.5825 arg-per-sent)\n",
      "\tunique: 12\n",
      "\tfor each: Counter({'ARG1': 68451, 'ARG0': 18568, 'ARG3': 11060, 'ARGM-LOC': 6468, 'ARG2': 4935, 'ARGM-MNR': 4098, 'ARGM-TMP': 3423, 'ARGM-EXT': 2986, 'ARGM-CAU': 1819, 'ARGM-INS': 1426, 'ARGM-DIR': 1357, 'ARGM-PRP': 282})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import read_data\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from optparse import OptionParser\n",
    "import torch.autograd as autograd\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "# from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "import eval_srl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './result/model-morp-sum'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "model_path = model_dir+'/model.pt'\n",
    "\n",
    "dev_sent = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "today = start_time.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = read_data.load_trn_data()\n",
    "trn_conll = read_data.load_trn_nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "# [\n",
    "#     ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'], \n",
    "#     ['인사동에', '들어서면', '다종다양의', '창호지,', '도자기', '등', '고미술품들이', '진열장에', '즐비하게', '널려져', '있는', '것을', '볼', '수', '있다.'], \n",
    "#     ['ARGM-LOC', '-', '-', '-', '-', '-', 'ARG1', 'ARG1', '-', '-', '-', 'ARG1', '-', '-', '-']\n",
    "# ]\n",
    "\n",
    "def get_input_data(data):\n",
    "    result = []\n",
    "    for sent in data:\n",
    "        sent_list = []\n",
    "        \n",
    "        tok_idx = []\n",
    "        tok_str = []\n",
    "        tok_arg = []\n",
    "        for token in sent:\n",
    "            tok_idx.append(token[0])\n",
    "            tok_str.append(token[1])\n",
    "            tok_arg.append(token[2])\n",
    "            \n",
    "        sent_list.append(tok_idx)\n",
    "        sent_list.append(tok_str)\n",
    "        sent_list.append(tok_arg)\n",
    "        result.append(sent_list)\n",
    "    return result\n",
    "        \n",
    "input_data = get_input_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### dev data: 500 sents\n"
     ]
    }
   ],
   "source": [
    "div = len(input_data) - dev_sent\n",
    "\n",
    "dev = input_data[div:]\n",
    "trn = input_data[:div]\n",
    "gold_file = './dev.data'\n",
    "print('')\n",
    "print('### dev data:', len(dev), 'sents')\n",
    "\n",
    "with open(gold_file,'w') as f:\n",
    "    dev_list = []\n",
    "    for i in dev:\n",
    "        dev_list += i[2]\n",
    "        \n",
    "    json.dump(dev_list, f)\n",
    "    \n",
    "gold_to_see = './dev.tosee'\n",
    "with open(gold_to_see,'w') as f:\n",
    "    dev_list = []\n",
    "    for i in dev:\n",
    "        dev_list.append(i[2])\n",
    "        \n",
    "    json.dump(dev_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_idx():\n",
    "    dp_to_ix, arg_to_ix, morp_to_ix = {},{},{}\n",
    "    dp_to_ix['null'] = 0\n",
    "    morp_to_ix['null'] = 0\n",
    "    \n",
    "    for sent in trn_conll:\n",
    "        for token in sent:\n",
    "            dp = token[11]\n",
    "            if dp not in dp_to_ix:\n",
    "                dp_to_ix[dp] = len(dp_to_ix)\n",
    "                \n",
    "            morphs = token[2].split('+')\n",
    "            for morp in morphs:\n",
    "                if morp not in morp_to_ix:\n",
    "                    morp_to_ix[morp] = len(morp_to_ix)\n",
    "    args = ['ARG0', 'ARG1', 'ARG2', 'ARG3', 'ARGM-CAU', 'ARGM-CND', 'ARGM-DIR', 'ARM-DIS', 'ARGM-INS', 'ARGM-LOC', 'ARCM-MNR', 'ARCM-NEG', 'ARCM-PRD', 'ARCM-PRP', 'ARCM-TMP', 'ARCM-ADV', 'ARCM-EXT', '-']\n",
    "    for i in args:\n",
    "        if i not in arg_to_ix:\n",
    "            arg_to_ix[i] = len(arg_to_ix)\n",
    "    return dp_to_ix, arg_to_ix, morp_to_ix\n",
    "dp_to_ix, arg_to_ix, morp_to_ix = prepare_idx()\n",
    "DP_VOCAB_SIZE = len(dp_to_ix)\n",
    "ARG_VOCAB_SIZE = len(arg_to_ix)\n",
    "MORP_VOCAB_SIZE = len(morp_to_ix)\n",
    "print('DP_VOCAB_SIZE:',DP_VOCAB_SIZE)\n",
    "print('ARG_VOCAB_SIZE:',ARG_VOCAB_SIZE)\n",
    "print('MORP_VOCAB_SIZE:', MORP_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "print('### loading word2vec model...')\n",
    "wv_model = KeyedVectors.load_word2vec_format(\"./wordembedding/100_dim_3_window_5mincount_word2vec.model\")\n",
    "print('... is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec(morp):\n",
    "    \n",
    "    vec = torch.rand(100)\n",
    "    emb = vec.cuda()\n",
    "    \n",
    "    try:\n",
    "        vec = wv_model[morp]\n",
    "        emb = torch.from_numpy(vec).cuda()\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        pass                \n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = {'token_dim': 60,\n",
    "                 'hidden_dim': 64,\n",
    "                 'feat_dim': 1,\n",
    "                 'dp_dim': 4,\n",
    "                 'arg_dim': 4,\n",
    "                 'lu_pos_dim': 5,\n",
    "                 'dp_label_dim': 10,\n",
    "                 'lstm_input_dim': 100,\n",
    "                 'lstm_dim': 64,\n",
    "                 'lstm_depth': 2,\n",
    "                 'hidden_dim': 64,\n",
    "                 'position_feature_dim': 5,\n",
    "                 'num_epochs': 13,\n",
    "                 'learning_rate': 0.001,\n",
    "                 'dropout_rate': 0.01,\n",
    "                 'pretrained_embedding_dim': 300,\n",
    "                 'model_dir': model_dir,\n",
    "                 'model_path': model_path,\n",
    "                 }\n",
    "print('\\n### CONFIGURATION ###\\n')\n",
    "pprint.pprint(configuration)\n",
    "print('')\n",
    "\n",
    "DPDIM = configuration['dp_dim']\n",
    "ARGDIM = configuration['arg_dim']\n",
    "LSTMINPDIM = configuration['lstm_input_dim']\n",
    "FEATDIM = configuration['feat_dim']\n",
    "HIDDENDIM = configuration['hidden_dim']\n",
    "LSTMDEPTH = configuration['lstm_depth']\n",
    "DROPOUT_RATE = configuration['dropout_rate']\n",
    "learning_rate = configuration['learning_rate']\n",
    "NUM_EPOCHS = configuration['num_epochs']\n",
    "\n",
    "print('\\n### YOUR MODEL WILL BE SAVED TO', model_path, '###\\n')\n",
    "\n",
    "with open(model_dir+'/config.json', 'w') as f:\n",
    "    json.dump(configuration, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_idxs(conll):\n",
    "    result = []\n",
    "    preds = [0 for i in range(len(conll))]\n",
    "    for i in range(len(conll)):\n",
    "        tok = conll[i]\n",
    "        if tok[10].startswith('V'):\n",
    "            preds = [0 for item in range(len(conll))]\n",
    "            preds[i] = 1\n",
    "            result.append(preds)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arg_idxs(pred_idx, conll):\n",
    "    arg_idxs = [0 for i in range(len(conll))]\n",
    "    for i in range(len(conll)):\n",
    "        tok = conll[i]\n",
    "        if int(tok[8]) == pred_idx:\n",
    "            arg_pos = tok[-1]\n",
    "            if arg_pos[:2] == 'NP':\n",
    "                arg_idxs[i] = 1\n",
    "                \n",
    "    return arg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(pred_idxs, conll):\n",
    "    result = []\n",
    "    for i in pred_idxs:\n",
    "#         print(i)\n",
    "        features = []\n",
    "        for j in range(len(i)):\n",
    "            pred_idx = i[j]\n",
    "#             if pred_idx == 1:\n",
    "#                 arg_idxs = get_arg_idxs(j, conll)\n",
    "        for j in range(len(i)):\n",
    "            feature = []                \n",
    "            feature.append(i[j])\n",
    "#             feature.append(arg_idxs[j])\n",
    "            features.append(feature)                \n",
    "        result.append(features)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    vocab = list(to_ix.keys())\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w in vocab:\n",
    "            idxs.append(to_ix[w])\n",
    "        else:\n",
    "            idxs.append(0)  \n",
    "\n",
    "    return torch.tensor(idxs).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dps(conll):\n",
    "    dps = []\n",
    "    for tok in conll:\n",
    "        dp = tok[10]\n",
    "        dps.append(dp)\n",
    "    return dps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vec(tokens, conll):\n",
    "    result = []\n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        morps = conll[i][2].split('+')\n",
    "#         morp_ix = prepare_sequence(morps, morp_to_ix)\n",
    "        result.append(morps)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dev eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_by_tensor(t):\n",
    "    value, indices = t.max(1)\n",
    "    score = pow(1, value)\n",
    "    labels = []\n",
    "    for i in indices:\n",
    "        for label, idx in arg_to_ix.items():\n",
    "            if idx == i:\n",
    "                pred = label\n",
    "                labels.append(pred)\n",
    "                break\n",
    "    return labels, score            \n",
    "        \n",
    "    pred = None\n",
    "    for label, idx in arg_to_ix.items():\n",
    "        if idx == indices:\n",
    "            pred = label\n",
    "            break\n",
    "    return pred, score\n",
    "\n",
    "def eval_dev(my_model):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dev_idx = len(input_data)-len(dev)\n",
    "        result = []\n",
    "        n = 0    \n",
    "\n",
    "        pred_file = model_dir+'/dev.result'\n",
    "        pred_result = open(pred_file,'w')\n",
    "        \n",
    "        with open(gold_to_see) as f:\n",
    "            gold_anno = json.load(f)\n",
    "\n",
    "        for s_idx in range(len(dev)):      \n",
    "            tokens, args = dev[s_idx][1], dev[s_idx][2]\n",
    "            args_in = prepare_sequence(args, arg_to_ix)  \n",
    "\n",
    "            conll = read_data.get_nlp_for_trn(s_idx+dev_idx)\n",
    "            dps = get_dps(conll)\n",
    "            dp_in = prepare_sequence(dps, dp_to_ix)\n",
    "\n",
    "            pred_idxs = get_pred_idxs(conll)\n",
    "            features = get_feature(pred_idxs, conll)\n",
    "            features = torch.tensor(features).type(torch.cuda.FloatTensor)\n",
    "\n",
    "            pred = ['-' for i in range(len(args))]\n",
    "\n",
    "            for i in range(len(pred_idxs)):\n",
    "                feat_vectors = features[i]            \n",
    "                input_sent = get_sentence_vec(tokens, conll)       \n",
    "\n",
    "                pred_seq = pred_idxs[i]\n",
    "                for j in range(len(pred_seq)):\n",
    "                    p = pred_seq[j]\n",
    "                    if p == 1:\n",
    "                        pred_idx = j\n",
    "                arg_idxs = get_arg_idxs(pred_idx, conll)\n",
    "                mask = torch.tensor(arg_idxs).cuda()\n",
    "                mask = mask.float()\n",
    "\n",
    "                tag_scores = srl_model(input_sent, dp_in, feat_vectors, mask)\n",
    "                labels, score = get_labels_by_tensor(tag_scores)\n",
    "\n",
    "                for idx in range(len(labels)):\n",
    "                    label = labels[idx]\n",
    "                    if label == '-':\n",
    "                        pass\n",
    "                    else:\n",
    "                        pred[idx] = label\n",
    "\n",
    "            pred_result.write(str(pred)+'\\n')\n",
    "            \n",
    "            annotation = []\n",
    "            annotation.append(tokens)\n",
    "            annotation.append(gold_anno[s_idx])\n",
    "            annotation.append(pred)\n",
    "\n",
    "            result.append(annotation)\n",
    "     \n",
    "    \n",
    "    with open(model_dir+'/dev-result.tosee','w') as f:\n",
    "        for i in result:\n",
    "            for j in i:\n",
    "                f.write(str(j)+'\\n')\n",
    "            f.write('\\n')\n",
    "    \n",
    "    pred_result.close()\n",
    "    with open(gold_file,'r') as f:\n",
    "        gold = json.load(f)\n",
    "        \n",
    "    \n",
    "    pred = eval_srl.read_prediction(pred_file)\n",
    "    f1 = eval_srl.evaluate_from_list(pred, gold)\n",
    "      \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.dp_embeddings = nn.Embedding(DP_VOCAB_SIZE, DPDIM)\n",
    "        \n",
    "        #LSTM layer        \n",
    "#         self.lstm_morp = nn.LSTM(LSTMINPDIM, HIDDENDIM//2, bidirectional=True, num_layers=LSTMDEPTH, dropout=DROPOUT_RATE)\n",
    "#         self.hidden_lstm_morp = self.init_hidden_lstm_morp()\n",
    "        \n",
    "        self.lstm_tok = nn.LSTM(LSTMINPDIM+DPDIM+FEATDIM, HIDDENDIM//2, bidirectional=True, num_layers=LSTMDEPTH, dropout=DROPOUT_RATE)\n",
    "        self.hidden_lstm_tok = self.init_hidden_lstm_tok()\n",
    "        \n",
    "        # Linear\n",
    "        self.hidden2tag = nn.Linear(HIDDENDIM, tagset_size)\n",
    "              \n",
    "\n",
    "#     def init_hidden_lstm_morp(self):\n",
    "#         return (torch.zeros(4, 1, HIDDENDIM//2).cuda(),\n",
    "#             torch.zeros(4, 1, HIDDENDIM//2).cuda())\n",
    "    \n",
    "    def init_hidden_lstm_tok(self):\n",
    "        return (torch.zeros(4, 1, HIDDENDIM//2).cuda(),\n",
    "            torch.zeros(4, 1, HIDDENDIM//2).cuda())\n",
    "    \n",
    "    def forward(self, input_sent, dp_in, feat_vectors, mask):\n",
    "        \n",
    "        dp_embs = self.dp_embeddings(dp_in)\n",
    "        \n",
    "#         LSTM layer 1 (subunit to token)\n",
    "        tok_vectors = []\n",
    "        for morps in input_sent:\n",
    "            wes = []\n",
    "            we = torch.zeros(100).cuda()\n",
    "            for morp in morps:\n",
    "                we += get_word2vec(morp)\n",
    "            tok_vectors.append(we)\n",
    "\n",
    "        tok_vec = torch.stack(tok_vectors)\n",
    "        tok_vec = tok_vec.view(len(tok_vec), -1)    \n",
    "        \n",
    "#         LSTM layer\n",
    "        input_embs = torch.cat( (tok_vec, dp_embs, feat_vectors), 1)\n",
    "        input_embs_2 = input_embs.view(len(input_embs), 1, -1)\n",
    "\n",
    "        lstm_out_tok, self.hidden_lstm_tok = self.lstm_tok(\n",
    "            input_embs_2, self.hidden_lstm_tok)\n",
    "        \n",
    "        # Linear\n",
    "        tag_space = self.hidden2tag(lstm_out_tok.view(len(input_embs_2),-1))  \n",
    "\n",
    "#         for t_idx in range(len(tag_space)):\n",
    "#             t = tag_space[t_idx]\n",
    "#             m = mask[t_idx]\n",
    "#             if m > 0:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 t[-1] = 1\n",
    "        \n",
    "        tag_space = F.relu(tag_space)        \n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        tag_scores = softmax(tag_space)\n",
    "        return tag_scores       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_model = LSTMTagger(ARG_VOCAB_SIZE)\n",
    "srl_model.cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(srl_model.parameters(), lr=learning_rate)\n",
    "# optimizer = optim.SGD(srl_model.parameters(), lr=learning_rate)\n",
    "\n",
    "epoch_dev_file = open(model_dir+'/epoch.dev', 'w')\n",
    "total_step = len(trn)\n",
    "\n",
    "print('training...')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    n_of_sent = 0\n",
    "    total_sent = len(trn)\n",
    "    for s_idx in range(len(trn)):\n",
    "        \n",
    "        tokens, args = trn[s_idx][1], trn[s_idx][2]\n",
    "\n",
    "        args_in = prepare_sequence(args, arg_to_ix)  \n",
    "\n",
    "        conll = read_data.get_nlp_for_trn(s_idx)\n",
    "        dps = get_dps(conll)\n",
    "        dp_in = prepare_sequence(dps, dp_to_ix)\n",
    "\n",
    "        pred_idxs = get_pred_idxs(conll)\n",
    "        features = get_feature(pred_idxs, conll)\n",
    "        features = torch.tensor(features).type(torch.cuda.FloatTensor)  \n",
    "\n",
    "        for i in range(len(pred_idxs)):\n",
    "            feat_vectors = features[i]            \n",
    "            input_sent = get_sentence_vec(tokens, conll)       \n",
    "            \n",
    "            pred_seq = pred_idxs[i]\n",
    "            for j in range(len(pred_seq)):\n",
    "                p = pred_seq[j]\n",
    "                if p == 1:\n",
    "                    pred_idx = j\n",
    "            arg_idxs = get_arg_idxs(pred_idx, conll)\n",
    "            mask = torch.tensor(arg_idxs).cuda()\n",
    "            mask = mask.float()\n",
    "            \n",
    "            srl_model.zero_grad()         \n",
    "            srl_model.hidden_lstm_tok = srl_model.init_hidden_lstm_tok()\n",
    "\n",
    "            tag_scores = srl_model(input_sent, dp_in, feat_vectors, mask)\n",
    "            loss = loss_function(tag_scores, args_in)\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(srl_model.parameters(), 0.25)\n",
    "            optimizer.step()\n",
    "            \n",
    "        n_of_sent +=1\n",
    "        \n",
    "        if n_of_sent % 100 == 0:\n",
    "            print('Epoch [{}/{}], Sent [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, NUM_EPOCHS, n_of_sent, total_sent, loss.item()))\n",
    "        \n",
    "#         break\n",
    "        \n",
    "    # EPOCH 마다 dev에 대한 성능 평가\n",
    "\n",
    "        \n",
    "    f1 = eval_dev(srl_model)\n",
    "    print('Epoch [{}/{}], F1: {:4f}' \n",
    "                   .format(epoch+1, NUM_EPOCHS, f1))\n",
    "    \n",
    "    line = 'epoch '+str(epoch+1)+': '+str(f1)+'\\n'\n",
    "    epoch_dev_file.write(line)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print('Duration: {}'.format(end_time - start_time))\n",
    "    print('')\n",
    "    \n",
    "    torch.save(srl_model, model_path)\n",
    "    \n",
    "#     break\n",
    "       \n",
    "torch.save(srl_model, model_path)\n",
    "print('')\n",
    "print('### YOUR MODEL IS SAVED TO', model_path, '###')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
