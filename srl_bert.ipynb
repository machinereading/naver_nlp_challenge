{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading TRAINING data...\n",
      "# of sentences: 34856\n",
      "# of arg_types\n",
      "\ttotal: 124873 (3.5825 arg-per-sent)\n",
      "\tunique: 12\n",
      "\tfor each: Counter({'ARG1': 68451, 'ARG0': 18568, 'ARG3': 11060, 'ARGM-LOC': 6468, 'ARG2': 4935, 'ARGM-MNR': 4098, 'ARGM-TMP': 3423, 'ARGM-EXT': 2986, 'ARGM-CAU': 1819, 'ARGM-INS': 1426, 'ARGM-DIR': 1357, 'ARGM-PRP': 282})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import read_data\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from optparse import OptionParser\n",
    "import torch.autograd as autograd\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "import eval_srl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './result/model-bert'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "model_path = model_dir+'/model.pt'\n",
    "\n",
    "dev_sent = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "today = start_time.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = read_data.load_trn_data()\n",
    "trn_conll = read_data.load_trn_nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "# [\n",
    "#     ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'], \n",
    "#     ['인사동에', '들어서면', '다종다양의', '창호지,', '도자기', '등', '고미술품들이', '진열장에', '즐비하게', '널려져', '있는', '것을', '볼', '수', '있다.'], \n",
    "#     ['ARGM-LOC', '-', '-', '-', '-', '-', 'ARG1', 'ARG1', '-', '-', '-', 'ARG1', '-', '-', '-']\n",
    "# ]\n",
    "\n",
    "def get_input_data(data):\n",
    "    result = []\n",
    "    for sent in data:\n",
    "        sent_list = []\n",
    "        \n",
    "        tok_idx = []\n",
    "        tok_str = []\n",
    "        tok_arg = []\n",
    "        for token in sent:\n",
    "            tok_idx.append(token[0])\n",
    "            tok_str.append(token[1])\n",
    "            tok_arg.append(token[2])\n",
    "            \n",
    "        sent_list.append(tok_idx)\n",
    "        sent_list.append(tok_str)\n",
    "        sent_list.append(tok_arg)\n",
    "        result.append(sent_list)\n",
    "    return result\n",
    "        \n",
    "input_data = get_input_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### dev data: 500 sents\n"
     ]
    }
   ],
   "source": [
    "div = len(input_data) - dev_sent\n",
    "\n",
    "dev = input_data[div:]\n",
    "trn = input_data[:div]\n",
    "gold_file = './dev.data'\n",
    "print('')\n",
    "print('### dev data:', len(dev), 'sents')\n",
    "\n",
    "with open(gold_file,'w') as f:\n",
    "    dev_list = []\n",
    "    for i in dev:\n",
    "        dev_list += i[2]\n",
    "        \n",
    "    json.dump(dev_list, f)\n",
    "    \n",
    "gold_to_see = './dev.tosee'\n",
    "with open(gold_to_see,'w') as f:\n",
    "    dev_list = []\n",
    "    for i in dev:\n",
    "        dev_list.append(i[2])\n",
    "        \n",
    "    json.dump(dev_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP_VOCAB_SIZE: 32\n",
      "ARG_VOCAB_SIZE: 18\n",
      "MORP_VOCAB_SIZE: 63376\n"
     ]
    }
   ],
   "source": [
    "def prepare_idx():\n",
    "    dp_to_ix, arg_to_ix, morp_to_ix = {},{},{}\n",
    "    dp_to_ix['null'] = 0\n",
    "    morp_to_ix['null'] = 0\n",
    "    \n",
    "    for sent in trn_conll:\n",
    "        for token in sent:\n",
    "            dp = token[11]\n",
    "            if dp not in dp_to_ix:\n",
    "                dp_to_ix[dp] = len(dp_to_ix)\n",
    "                \n",
    "            morphs = token[2].split('+')\n",
    "            for morp in morphs:\n",
    "                if morp not in morp_to_ix:\n",
    "                    morp_to_ix[morp] = len(morp_to_ix)\n",
    "    args = ['ARG0', 'ARG1', 'ARG2', 'ARG3', 'ARGM-CAU', 'ARGM-CND', 'ARGM-DIR', 'ARM-DIS', 'ARGM-INS', 'ARGM-LOC', 'ARCM-MNR', 'ARCM-NEG', 'ARCM-PRD', 'ARCM-PRP', 'ARCM-TMP', 'ARCM-ADV', 'ARCM-EXT', '-']\n",
    "    for i in args:\n",
    "        if i not in arg_to_ix:\n",
    "            arg_to_ix[i] = len(arg_to_ix)\n",
    "    return dp_to_ix, arg_to_ix, morp_to_ix\n",
    "dp_to_ix, arg_to_ix, morp_to_ix = prepare_idx()\n",
    "DP_VOCAB_SIZE = len(dp_to_ix)\n",
    "ARG_VOCAB_SIZE = len(arg_to_ix)\n",
    "MORP_VOCAB_SIZE = len(morp_to_ix)\n",
    "print('DP_VOCAB_SIZE:',DP_VOCAB_SIZE)\n",
    "print('ARG_VOCAB_SIZE:',ARG_VOCAB_SIZE)\n",
    "print('MORP_VOCAB_SIZE:', MORP_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### CONFIGURATION ###\n",
      "\n",
      "{'arg_dim': 4,\n",
      " 'dp_dim': 4,\n",
      " 'dp_label_dim': 10,\n",
      " 'dropout_rate': 0.01,\n",
      " 'feat_dim': 1,\n",
      " 'hidden_dim': 64,\n",
      " 'learning_rate': 0.001,\n",
      " 'lstm_depth': 2,\n",
      " 'lstm_dim': 64,\n",
      " 'lstm_input_dim': 100,\n",
      " 'lu_pos_dim': 5,\n",
      " 'model_dir': './result/model-bert',\n",
      " 'model_path': './result/model-bert/model.pt',\n",
      " 'num_epochs': 10,\n",
      " 'position_feature_dim': 5,\n",
      " 'pretrained_embedding_dim': 300,\n",
      " 'token_dim': 60}\n",
      "\n",
      "\n",
      "### YOUR MODEL WILL BE SAVED TO ./result/model-bert/model.pt ###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configuration = {'token_dim': 60,\n",
    "                 'feat_dim': 1,\n",
    "                 'dp_dim': 4,\n",
    "                 'arg_dim': 4,\n",
    "                 'lu_pos_dim': 5,\n",
    "                 'dp_label_dim': 10,\n",
    "                 'lstm_input_dim': 100,\n",
    "                 'lstm_dim': 64,\n",
    "                 'lstm_depth': 2,\n",
    "                 'hidden_dim': 64,\n",
    "                 'position_feature_dim': 5,\n",
    "                 'num_epochs': 10,\n",
    "                 'learning_rate': 0.001,\n",
    "                 'dropout_rate': 0.01,\n",
    "                 'pretrained_embedding_dim': 300,\n",
    "                 'model_dir': model_dir,\n",
    "                 'model_path': model_path,\n",
    "                 }\n",
    "print('\\n### CONFIGURATION ###\\n')\n",
    "pprint.pprint(configuration)\n",
    "print('')\n",
    "\n",
    "DPDIM = configuration['dp_dim']\n",
    "ARGDIM = configuration['arg_dim']\n",
    "LSTMINPDIM = configuration['lstm_input_dim']\n",
    "FEATDIM = configuration['feat_dim']\n",
    "HIDDENDIM = configuration['hidden_dim']\n",
    "LSTMDEPTH = configuration['lstm_depth']\n",
    "DROPOUT_RATE = configuration['dropout_rate']\n",
    "learning_rate = configuration['learning_rate']\n",
    "NUM_EPOCHS = configuration['num_epochs']\n",
    "\n",
    "print('\\n### YOUR MODEL WILL BE SAVED TO', model_path, '###\\n')\n",
    "\n",
    "with open(model_dir+'/config.json', 'w') as f:\n",
    "    json.dump(configuration, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_idxs(conll):\n",
    "    result = []\n",
    "    preds = [0 for i in range(len(conll))]\n",
    "    for i in range(len(conll)):\n",
    "        tok = conll[i]\n",
    "        if tok[10].startswith('V'):\n",
    "            preds = [0 for item in range(len(conll))]\n",
    "            preds[i] = 1\n",
    "            result.append(preds)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arg_idxs(pred_idx, conll):\n",
    "    arg_idxs = [0 for i in range(len(conll))]\n",
    "    for i in range(len(conll)):\n",
    "        tok = conll[i]\n",
    "        if int(tok[8]) == pred_idx:\n",
    "            \n",
    "#             arg_idxs[i] = 1\n",
    "            \n",
    "            arg_pos = tok[-1]\n",
    "            if arg_pos[:2] == 'NP':\n",
    "                arg_idxs[i] = 1\n",
    "                \n",
    "    return arg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(pred_idxs, conll):\n",
    "    result = []\n",
    "    for i in pred_idxs:\n",
    "        features = []\n",
    "        for j in range(len(i)):\n",
    "            pred_idx = i[j]\n",
    "        for j in range(len(i)):\n",
    "            feature = []                \n",
    "            feature.append(i[j])\n",
    "            features.append(feature)                \n",
    "        result.append(features)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    vocab = list(to_ix.keys())\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w in vocab:\n",
    "            idxs.append(to_ix[w])\n",
    "        else:\n",
    "            idxs.append(0)  \n",
    "\n",
    "    return torch.tensor(idxs).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dps(conll):\n",
    "    dps = []\n",
    "    for tok in conll:\n",
    "        dp = tok[10]\n",
    "        dps.append(dp)\n",
    "    return dps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vec(tokens, conll):\n",
    "    result = []\n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        morps = conll[i][2].split('+')\n",
    "#         morp_ix = prepare_sequence(morps, morp_to_ix)\n",
    "        result.append(morps)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/12/2018 14:11:34 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/hahmyg/.pytorch_pretrained_bert/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "12/12/2018 14:11:35 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz from cache at /home/hahmyg/.pytorch_pretrained_bert/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9\n",
      "12/12/2018 14:11:35 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/hahmyg/.pytorch_pretrained_bert/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9 to temp dir /tmp/tmpp4d33f_7\n",
      "12/12/2018 14:11:40 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 만약 한국어를 쓸 경우 - uncased\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕하세요?', '저는', '한국인', '입니다.']\n",
      "['[CLS]', '안', '##녕', '##하', '##세', '##요', '?', '저', '##는', '한국', '##인', '입', '##니다', '.', '[SEP]']\n",
      "[1, 7, 9, 11]\n"
     ]
    }
   ],
   "source": [
    "def bert_tokenizer(text):\n",
    "    orig_tokens = text.split(' ')\n",
    "    bert_tokens = []\n",
    "    orig_to_tok_map = []\n",
    "    bert_tokens.append(\"[CLS]\")\n",
    "    for orig_token in orig_tokens:\n",
    "        orig_to_tok_map.append(len(bert_tokens))\n",
    "        bert_tokens.extend(tokenizer.tokenize(orig_token))\n",
    "    bert_tokens.append(\"[SEP]\")\n",
    "    \n",
    "    return orig_tokens, bert_tokens, orig_to_tok_map\n",
    "\n",
    "# text = '안녕하세요? 저는 한국인 입니다.'\n",
    "# orig_tokens, bert_tokens, orig_to_tok_map = bert_tokenizer(text)\n",
    "\n",
    "# print(orig_tokens)\n",
    "# print(bert_tokens)\n",
    "# print(orig_to_tok_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕하세요?', '저는', '한국인', '입니다.']\n",
      "['[CLS]', '안', '##녕', '##하', '##세', '##요', '?', '저', '##는', '한국', '##인', '입', '##니다', '.', '[SEP]']\n",
      "[1, 7, 9, 11]\n",
      "[101, 9521, 118741, 35506, 24982, 48549, 136, 9663, 11018, 48556, 12030, 9645, 48345, 119, 102]\n",
      "tensor([[   101,   9521, 118741,  35506,  24982,  48549,    136,   9663,  11018,\n",
      "          48556,  12030,   9645,  48345,    119,    102]])\n"
     ]
    }
   ],
   "source": [
    "text = '안녕하세요? 저는 한국인 입니다.'\n",
    "orig_tokens, bert_tokens, orig_to_tok_map = bert_tokenizer(text)\n",
    "\n",
    "print(orig_tokens)\n",
    "print(bert_tokens)\n",
    "print(orig_to_tok_map)\n",
    "\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "print(indexed_tokens)\n",
    "print(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.LongTensor([[31, 51, 99]])\n",
    "input_mask = torch.LongTensor([[0, 1, 2]])\n",
    "token_type_ids = torch.LongTensor([[0, 0, 0]])\n",
    "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
    "num_labels = 3\n",
    "model = BertForTokenClassification(config, num_labels)\n",
    "logits = model(input_ids, token_type_ids, input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0013, -0.0269, -0.0012],\n",
      "         [ 0.0144, -0.0177, -0.0063],\n",
      "         [ 0.0164, -0.0211, -0.0155]]], grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
