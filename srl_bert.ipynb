{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import read_data\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from optparse import OptionParser\n",
    "import torch.autograd as autograd\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, modeling\n",
    "# from pytorch_pretrained_bert.modeling import BertForTokenClassification\n",
    "\n",
    "import eval_srl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import gluonnlp as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './result/model-bert'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "model_path = model_dir+'/model.pt'\n",
    "\n",
    "dev_sent = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "today = start_time.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = read_data.load_trn_data()\n",
    "trn_conll = read_data.load_trn_nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "# [\n",
    "#     ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'], \n",
    "#     ['인사동에', '들어서면', '다종다양의', '창호지,', '도자기', '등', '고미술품들이', '진열장에', '즐비하게', '널려져', '있는', '것을', '볼', '수', '있다.'], \n",
    "#     ['ARGM-LOC', '-', '-', '-', '-', '-', 'ARG1', 'ARG1', '-', '-', '-', 'ARG1', '-', '-', '-']\n",
    "# ]\n",
    "\n",
    "def get_input_data(data):\n",
    "    result = []\n",
    "    for sent in data:\n",
    "        sent_list = []\n",
    "        \n",
    "        tok_idx = []\n",
    "        tok_str = []\n",
    "        tok_arg = []\n",
    "        for token in sent:\n",
    "            tok_idx.append(token[0])\n",
    "            tok_str.append(token[1])\n",
    "            tok_arg.append(token[2])\n",
    "            \n",
    "        sent_list.append(tok_idx)\n",
    "        sent_list.append(tok_str)\n",
    "        sent_list.append(tok_arg)\n",
    "        result.append(sent_list)\n",
    "    return result\n",
    "        \n",
    "input_data = get_input_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen TRN and DEV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev data: 100 sents\n"
     ]
    }
   ],
   "source": [
    "div = len(input_data) - dev_sent\n",
    "\n",
    "dev = input_data[div:]\n",
    "trn = input_data[:div]\n",
    "gold_file = './dev.data'\n",
    "print('dev data:', len(dev), 'sents')\n",
    "\n",
    "with open(gold_file,'w') as f:\n",
    "    dev_list = []\n",
    "    for i in dev:\n",
    "        dev_list += i[2]\n",
    "        \n",
    "    json.dump(dev_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP_VOCAB_SIZE: 32\n",
      "ARG_VOCAB_SIZE: 18\n",
      "MORP_VOCAB_SIZE: 63376\n"
     ]
    }
   ],
   "source": [
    "def prepare_idx():\n",
    "    dp_to_ix, arg_to_ix, morp_to_ix = {},{},{}\n",
    "    dp_to_ix['null'] = 0\n",
    "    morp_to_ix['null'] = 0\n",
    "    \n",
    "    for sent in trn_conll:\n",
    "        for token in sent:\n",
    "            dp = token[11]\n",
    "            if dp not in dp_to_ix:\n",
    "                dp_to_ix[dp] = len(dp_to_ix)\n",
    "                \n",
    "            morphs = token[2].split('+')\n",
    "            for morp in morphs:\n",
    "                if morp not in morp_to_ix:\n",
    "                    morp_to_ix[morp] = len(morp_to_ix)\n",
    "    args = ['ARG0', 'ARG1', 'ARG2', 'ARG3', 'ARGM-CAU', 'ARGM-CND', 'ARGM-DIR', 'ARM-DIS', 'ARGM-INS', 'ARGM-LOC', 'ARCM-MNR', 'ARCM-NEG', 'ARCM-PRD', 'ARCM-PRP', 'ARCM-TMP', 'ARCM-ADV', 'ARCM-EXT', '-']\n",
    "    for i in args:\n",
    "        if i not in arg_to_ix:\n",
    "            arg_to_ix[i] = len(arg_to_ix)\n",
    "    return dp_to_ix, arg_to_ix, morp_to_ix\n",
    "dp_to_ix, arg_to_ix, morp_to_ix = prepare_idx()\n",
    "DP_VOCAB_SIZE = len(dp_to_ix)\n",
    "ARG_VOCAB_SIZE = len(arg_to_ix)\n",
    "MORP_VOCAB_SIZE = len(morp_to_ix)\n",
    "print('DP_VOCAB_SIZE:',DP_VOCAB_SIZE)\n",
    "print('ARG_VOCAB_SIZE:',ARG_VOCAB_SIZE)\n",
    "print('MORP_VOCAB_SIZE:', MORP_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/10/2018 21:55:15 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-vocab.txt from cache at /home/hahmyg/.pytorch_pretrained_bert/3f396e8b6d1942457b908bd7f351fa991ead4c4adef76c76189a9ace12841860.535306b226c42cebebbc0dabc83b92ab11260e9919e21e2ab0beb301f267b4c7\n",
      "12/10/2018 21:55:16 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual.tar.gz from cache at /home/hahmyg/.pytorch_pretrained_bert/e359baa6e6b29d9971ac7525c83e8cad6f15dce9d8ec9bfdeafa149a7a2191c9.5e2593d7d76d4df2b618714d71af902c02a5f51c1b2d050399e1cb36b7bb2eeb\n",
      "12/10/2018 21:55:16 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/hahmyg/.pytorch_pretrained_bert/e359baa6e6b29d9971ac7525c83e8cad6f15dce9d8ec9bfdeafa149a7a2191c9.5e2593d7d76d4df2b618714d71af902c02a5f51c1b2d050399e1cb36b7bb2eeb to temp dir /tmp/tmpla1t_kn3\n",
      "12/10/2018 21:55:20 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual')\n",
    "bert_model = BertModel.from_pretrained('bert-base-multilingual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(tokens):\n",
    "    bert_tokens = []\n",
    "    orig_to_token_map = []\n",
    "    bert_tokens.append(\"[CLS]\")\n",
    "    for i in range(len(tokens)):\n",
    "        origin_token = tokens[i]\n",
    "        orig_to_token_map.append(len(bert_tokens))\n",
    "        bert_tokens.extend(tokenizer.tokenize(origin_token))\n",
    "    \n",
    "    return bert_tokens, orig_to_token_map  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_idxs(conll):\n",
    "    result = []\n",
    "    preds = [0 for i in range(len(conll))]\n",
    "    for i in range(len(conll)):\n",
    "        tok = conll[i]\n",
    "        if tok[10].startswith('V'):\n",
    "            preds = [0 for item in range(len(conll))]\n",
    "            preds[i] = 1\n",
    "            result.append(preds)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arg_idxs(pred_idx, conll):\n",
    "    arg_idxs = [0 for i in range(len(conll))]\n",
    "    for i in range(len(conll)):\n",
    "        tok = conll[i]\n",
    "        if int(tok[8]) == pred_idx:\n",
    "            arg_pos = tok[-1]\n",
    "            if arg_pos[:2] == 'NP':\n",
    "                arg_idxs[i] = 1\n",
    "                \n",
    "    return arg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(pred_idxs, conll):\n",
    "    result = []\n",
    "    for i in pred_idxs:\n",
    "#         print(i)\n",
    "        features = []\n",
    "        for j in range(len(i)):\n",
    "            pred_idx = i[j]\n",
    "            if pred_idx == 1:\n",
    "                arg_idxs = get_arg_idxs(j, conll)\n",
    "#                 print(arg_idxs)\n",
    "        for j in range(len(i)):\n",
    "            feature = []                \n",
    "            feature.append(i[j])\n",
    "            feature.append(arg_idxs[j])\n",
    "            features.append(feature)                \n",
    "        result.append(features)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    vocab = list(to_ix.keys())\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w in vocab:\n",
    "            idxs.append(to_ix[w])\n",
    "        else:\n",
    "            idxs.append(0)  \n",
    "\n",
    "    return torch.tensor(idxs).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dps(conll):\n",
    "    dps = []\n",
    "    for tok in conll:\n",
    "        dp = tok[10]\n",
    "        dps.append(dp)\n",
    "    return dps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
